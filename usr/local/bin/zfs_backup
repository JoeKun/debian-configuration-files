#! /bin/bash
#
#  zfs_backup
#
#  Created by Joel Lopes Da Silva on 5/13/13.
#  Copyright Â© 2013 Joel Lopes Da Silva. All rights reserved.
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#  
#        http://www.apache.org/licenses/LICENSE-2.0
#  
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
#

# zfs_backup: perform backups of ZFS datasets, compresses them, encrypts 
#             them and splits them into chunks before sending them to 
#             remote machine; performs full backup for the first time, 
#             and incremental backups for subsequent invocations.
# 
# Requires zfs, bash, grep, basename, hostname, date, sed, mktemp, tee, shasum, bzip2, openssl, split.
# This was only tested on Debian GNU/kFreeBSD Wheezy.
# 
# WARNING: In my brief testing, I have hit data integrity issues with 
#          the output of this script. In its current state, I do not 
#          recommend people to use this script.
# 
# Instructions for restoring:
# zpool create data/backup_destination
# umount data/backup_destination
# cat ${dump_file_path}.bz2.enc-part-* | openssl enc -${encryption_algorithm} -d -pass "file:${encryption_password_file}" | bzip2 --decompress --stdout | zfs receive -Fduv data/backup_destination

# TODO:
#      - create file with SHA1 hashes of everything;
#      - create zfs_restore.

#-----------------------------------------------------------
# Default options
#-----------------------------------------------------------

default_encryption_algorithm="aes-256-cbc"


#-----------------------------------------------------------
# Parsing command line arguments
#-----------------------------------------------------------

function print_usage() {
    cat <<USAGE
Usage: ${0} [OPTIONS] first_dataset [second_dataset [...]]

The following options are optional:

  --force-full-backup                  perform a full backup even if we
                                       could have performed an incremental
                                       backup.
  --compression-algorithm=<algorithm>  desired compression algorithm;
                                       only two values are supported:
                                       bzip2 and none; defaults to none.
  --encryption-password-file=<path>    path to file containing password for
                                       encryption; if this option is not
                                       specified, encryption is disabled.
  --encryption-algorithm=<cipher>      name of OpenSSL cipher for encryption;
                                       if not specified, ${default_encryption_algorithm} will be
                                       used.
  --split-files-size=<size in bytes>   if specified, large ZFS dumps will
                                       be split into chunks no larger than
                                       this size; this uses the same
                                       format as the --bytes option of the
                                       split command line tool.
  --temporary-storage-directory=<path> path to directory for temporarily
                                       storing the compressed and encrypted
                                       output files; you must have ample
                                       available disk space at that location;
                                       if not specified, some temporary
                                       directory will automatically be
                                       created.
  --keep-old-snapshot                  do not destroy previous snapshot
                                       after performing incremental backup.
  --silent                             do not log progress to stdout.
  -h, --help                           print this help message and exit.

Example:

  ${0} \\
    --compression-algorithm=bzip2                          \\
    --encryption-password-file=/path/to/file_with_password \\
    --encryption-algorithm=aes-128-cbc                     \\
    --split-files-size=100m                                \\
    --temporary-storage-directory=/backups                 \\
    tank/home tank/var
USAGE
}

function extract_value_for_option() {
    typeset variable_name full_argument option_name value
    variable_name="${1}"
    full_argument="${2}"
    option_name=$(echo "${variable_name}" | sed "s/_/-/g")
    case ${full_argument} in
        --${option_name}=*)
            value=$(echo "${full_argument}" | sed "s/^--${option_name}=\(.*\)$/\1/g" | sed "s/^\"\(.*\)\"$/\1/g")
            eval ${variable_name}="${value}"
            ;;
        *)
            ;;
    esac
}

function bail_with_error_message() {
    echo "Error: ${1}."
    exit 1
}

function bail_with_error_message_and_usage() {
    echo "Error: ${1}."
    print_usage
    exit 1
}

datasets=()
temporary_storage_directory=""
compression_algorithm=""
encryption_algorithm=""
encryption_password_file=""
split_files_size=""
force_full_backup=0
keep_old_snapshot=0
silent=0
for argument in "$@"
do
    case ${argument} in
        -h|-help|--help|help) print_usage; exit 0;;
        --silent)             silent=1;;
        --force-full-backup)  force_full_backup=1;;
        --keep-old-snapshot)  keep_old_snapshot=1;;
        --*)
            extract_value_for_option temporary_storage_directory "${argument}"
            extract_value_for_option compression_algorithm       "${argument}"
            extract_value_for_option encryption_algorithm        "${argument}"
            extract_value_for_option encryption_password_file    "${argument}"
            extract_value_for_option split_files_size            "${argument}"
            ;;
         *)
            zfs list -H -o name | grep "^${argument}$" > /dev/null || bail_with_error_message "ZFS dataset named \"${argument}\" doesn't exist"
            datasets+=( "${argument}" )
            ;;
    esac
done

# Checking datasets
[ ${#datasets[@]} -gt 0 ] || bail_with_error_message_and_usage "you need to specify at least one ZFS dataset to backup"

# Checking encryption_algorithm
[ -n "${encryption_algorithm}" ] || encryption_algorithm="${default_encryption_algorithm}"
openssl list-cipher-algorithms | grep --ignore-case "^${encryption_algorithm}$" > /dev/null || bail_with_error_message "OpenSSL cipher ${encryption_algorithm} is not supported on this machine"

# Checking encryption_password_file
if [ -n "${encryption_password_file}" ]
then
    [ -f "${encryption_password_file}" ] || bail_with_error_message "missing OpenSSL encryption password file; expected at path ${encryption_password_file}"
    [ -r "${encryption_password_file}" ] || bail_with_error_message "can't read OpenSSL encryption password file at path ${encryption_password_file}"
    openssl_encryption_password=$(cat "${encryption_password_file}")
    [ -n "${openssl_encryption_password}" ] || bail_with_error_message "OpenSSL encryption password file ${encryption_password_file} was empty"
    unset openssl_encryption_password
fi

# Checking temporary_storage_directory
should_create_temporary_storage_directory=0
dump_file_directory_path="${temporary_storage_directory}"
if [ -n "${temporary_storage_directory}" ]
then
    [ -d "${temporary_storage_directory}" ] || bail_with_error_message "temporary storage directory is missing; expected at location: ${temporary_storage_directory}"
    [ -w "${temporary_storage_directory}" ] || bail_with_error_message "can't write to temporary storage directory at location: ${temporary_storage_directory}"
    dump_file_directory_path=$(mktemp --directory --tmpdir="${temporary_storage_directory}")
else
    should_create_temporary_storage_directory=1
    temporary_storage_directory=$(mktemp --directory)
fi


#-----------------------------------------------------------
# Logging routines
#-----------------------------------------------------------

function log_dataset_backup_began_introduction() {
    if [ ${silent} -eq 0 ]
    then
        echo "${1}"
        echo "${1}" | sed "s/./-/g"
        echo 
    fi
}

function log_dataset_backup_ended_spacing() {
    if [ ${silent} -eq 0 ]
    then
        echo
        echo
    fi
}

function log_step_began() {
    [ ${silent} -eq 0 ] && echo -n "${1}... "
}

function log_step_ended() {
    [ ${silent} -eq 0 ] && echo "done."
}


#-----------------------------------------------------------
# Routines for processing backup data
#-----------------------------------------------------------

function send_zfs_stream() {
    typeset dataset last_backup_snapshot_name
    dataset="${1}"
    last_backup_snapshot_name="${2}"
    if [ "${last_backup_snapshot_name}" != "-" ]
    then
        zfs send -R -I "${dataset}@${last_backup_snapshot_name}" "${dataset}@${new_snapshot_name}"
    else
        zfs send -R "${dataset}@${new_snapshot_name}"
    fi
}

function spawn_checksum_computation_of_stream() {
    typeset dump_file_path
    dump_file_path="${1}"
    tee >( shasum --algorithm 1 | cut -d " " -f 1 > "${dump_file_path}.sha1" )
}

function compress_stream_if_appropriate() {
    if [ "${compression_algorithm}" == "bzip2" ]
    then
        bzip2 --compress --stdout
    else
        cat
    fi
}

function encrypt_stream_if_appropriate() {
    if [ -n "${encryption_password_file}" ]
    then
        openssl enc -${encryption_algorithm} -e -pass "file:${encryption_password_file}"
    else
        cat
    fi
}

function store_stream_splitting_into_chunks_if_appropriate() {
    typeset dump_file_path dump_file_path_with_extension
    dump_file_path="${1}"
    dump_file_path_with_extension="${dump_file_path}"
    [ "${compression_algorithm}" == "bzip2" ] && dump_file_path_with_extension="${dump_file_path_with_extension}.bz2"
    [ -n "${encryption_password_file}" ]      && dump_file_path_with_extension="${dump_file_path_with_extension}.enc"
    if [ -n "${split_files_size}" ]
    then
        split --bytes=${split_files_size} --numeric-suffixes - "${dump_file_path_with_extension}.part-"
    else
        cat > "${dump_file_path_with_extension}"
    fi
}


#-----------------------------------------------------------
# Other constants
#-----------------------------------------------------------

snapshot_name_prefix="backup_"
machine_name=$(hostname --short)
last_backup_snapshot_user_property="${machine_name}:last_backup_snapshot"
date_components=$(date +"%Y_%m_%d__%H_%M_%S")
year=$(echo "${date_components}" | cut -d "_" -f 1)
month=$(echo "${date_components}" | cut -d "_" -f 2)
day=$(echo "${date_components}" | cut -d "_" -f 3)
formatted_date=$(echo "${date_components}" | sed "s/_\([^_]\)/\1/g")
new_snapshot_name="${snapshot_name_prefix}${formatted_date}"


#-----------------------------------------------------------
# Backup work
#-----------------------------------------------------------

# Backup datasets one at a time
handling_first_dataset=1
for dataset in "${datasets[@]}"
do
    
    # Log introduction
    if [ ${handling_first_dataset} -eq 1 ]
    then
        handling_first_dataset=0
    else
        log_dataset_backup_ended_spacing
    fi
    log_dataset_backup_began_introduction "Backup ZFS dataset ${dataset}"
    
    # Create new snapshot
    log_step_began "Creating snapshot ${dataset}@${new_snapshot_name}"
    zfs snapshot -r "${dataset}@${new_snapshot_name}"
    log_step_ended
    
    # Find last backup snapshot and build dump file path
    last_backup_snapshot_name="-"
    if [ ${force_full_backup} -eq 0 ]
    then
        last_backup_snapshot_name=$(zfs get -H -o value "${last_backup_snapshot_user_property}" "${dataset}")
        if [ "${last_backup_snapshot_name}" != "-" ] && ! zfs list -H -o name -t snapshot | grep "^${dataset}@${last_backup_snapshot_name}$" > /dev/null
        then
            echo "Warning: couldn't find snapshot ${dataset}@${last_backup_snapshot_name}; falling back to full backup."
            last_backup_snapshot_name="-"
        fi
    fi
    dump_file_name=$(echo "${machine_name}_${dataset}" | sed "s/\//:/g")
    if [ "${last_backup_snapshot_name}" != "-" ]
    then
        dump_file_name="${dump_file_name}@${last_backup_snapshot_name}-${new_snapshot_name}-incremental.zdump"
    else
        dump_file_name="${dump_file_name}@${new_snapshot_name}-full.zdump"
    fi
    dump_file_path="${dump_file_directory_path}/${dump_file_name}"
    
    # Dump ZFS dataset information and post process it
    log_step_began "Dumping to ${dump_file_path}"
    send_zfs_stream "${dataset}" "${last_backup_snapshot_name}"               | \
        spawn_checksum_computation_of_stream "${dump_file_path}"              | \
        compress_stream_if_appropriate                                        | \
        encrypt_stream_if_appropriate                                         | \
        store_stream_splitting_into_chunks_if_appropriate "${dump_file_path}"
    log_step_ended
    
    # Destroy old snapshot
    if [ "${last_backup_snapshot_name}" != "-" ] && [ ${keep_old_snapshot} -eq 0 ]
    then
        log_step_began "Destroying old snapshot ${dataset}@${last_backup_snapshot_name}"
        zfs destroy -r "${dataset}@${last_backup_snapshot_name}"
        log_step_ended
    fi
    
    # Mark new snapshot as last backup snapshot
    log_step_began "Marking ${new_snapshot_name} as last backup snapshot"
    zfs set "${last_backup_snapshot_user_property}=${new_snapshot_name}" "${dataset}"
    log_step_ended
    
done

# FIXME: Actually scp files over to a remote server
log_step_began "Moving ${dump_file_path} to /data/backups/${year}/${month}/${day}"
mkdir --parents "/data/backups/${year}/${month}/${day}"
pushd "${dump_file_directory_path}" > /dev/null
cp -a * "/data/backups/${year}/${month}/${day}"
popd > /dev/null
log_step_ended

# Cleaning up temporary storage directory
log_step_began "Cleaning up temporary storage directory"
if [ $should_create_temporary_storage_directory -eq 1 ]
then
    rm --recursive --force "${temporary_storage_directory}"
else
    rm --recursive --force "${dump_file_directory_path}"
fi
log_step_ended

